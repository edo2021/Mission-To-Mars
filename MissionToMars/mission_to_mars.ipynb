{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 91.0.4472\n",
      "[WDM] - Get LATEST driver version for 91.0.4472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\zoom_\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store website\n",
    "\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How NASA's Mars Helicopter Will Reach the Red Planet's Surface\n",
      "The small craft will seek to prove that powered, controlled flight is possible on another planet. But just getting it onto the surface of Mars will take a whole lot of ingenuity.\n"
     ]
    }
   ],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain mars article information\n",
    "mars_results = soup.find_all('div', class_='col-md-8')\n",
    "\n",
    "mars_title = []\n",
    "mars_teaser = []\n",
    "\n",
    "# Identify the title and teaser article in each article\n",
    "for result in mars_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title\n",
    "        title = result.find('div', class_='content_title').text\n",
    "        #identify and return the teaser article\n",
    "        teaser = result.find('div', class_='article_teaser_body').text\n",
    "        mars_title.append(title)\n",
    "        mars_teaser.append(teaser)\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")\n",
    "        \n",
    "        \n",
    "browser.quit()        \n",
    "print(mars_title[0])\n",
    "print(mars_teaser[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store featured image website\n",
    "new_browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "image_url = \"https://spaceimages-mars.com/\"\n",
    "new_browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "new_html = new_browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "new_soup = BeautifulSoup(new_html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements that contain header image information\n",
    "image_results = new_soup.find_all('img', class_='headerimage fade-in')\n",
    "image_results\n",
    "\n",
    "#store featured URL info\n",
    "featured_url = []\n",
    "\n",
    "\n",
    "# Identify the featured image url\n",
    "for result in image_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title\n",
    "        featured_img = result['src']\n",
    "\n",
    "        featured_url.append(featured_img)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")\n",
    "        \n",
    "new_browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store featured image in a variable\n",
    "\n",
    "featured_image_url = \"https://spaceimages-mars.com/\" + featured_url[0]\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = \"https://galaxyfacts-mars.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas's \"read_html\"\n",
    "\n",
    "tables = pd.read_html(facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the table to a dataframe\n",
    "\n",
    "facts_df = tables[0]\n",
    "# facts_df.columns = ['']\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df.columns = ['','Mars','Earth']\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame({\"\":\"Description\", \" \":\" \", \" \":\" \"}, index=[0])\n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df = pd.concat([new_row, facts_df[:]]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df = facts_df.fillna(\" \")\n",
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df = facts_df.set_index(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_url = \"https://marshemispheres.com/\"\n",
    "valles_url = hemi_url +\"valles.html\"\n",
    "cerbrus_url = hemi_url +\"cerberus.html\"\n",
    "schia_url = hemi_url +\"schiaparelli.html\"\n",
    "syrt_url = hemi_url +\"syrtis.html\"\n",
    "\n",
    "#create browsers for each hemisphere\n",
    "valles_browser = Browser('chrome', **executable_path, headless=True)\n",
    "cerb_browser = Browser('chrome', **executable_path, headless=True)\n",
    "schia_browser = Browser('chrome', **executable_path, headless=True)\n",
    "syrt_browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "\n",
    "valles_browser.visit(valles_url)\n",
    "cerb_browser.visit(cerbrus_url)\n",
    "schia_browser.visit(schia_url)\n",
    "syrt_browser.visit(syrt_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valles_html = valles_browser.html\n",
    "cerb_html = cerb_browser.html\n",
    "schia_html = schia_browser.html\n",
    "syrt_html = syrt_browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "valles_soup = BeautifulSoup(valles_html, 'html.parser')\n",
    "cerb_soup = BeautifulSoup(cerb_html, 'html.parser')\n",
    "schia_soup = BeautifulSoup(schia_html, 'html.parser')\n",
    "syrt_soup = BeautifulSoup(syrt_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valles_results = valles_soup.find_all('div', class_=\"container\")\n",
    "cerb_results = cerb_soup.find_all('div', class_=\"container\")\n",
    "schia_results = schia_soup.find_all('div', class_=\"container\")\n",
    "syrt_results = syrt_soup.find_all('div', class_=\"container\")\n",
    "\n",
    "\n",
    "#create list to store title and hemi_image_url\n",
    "hemi_title = []\n",
    "hemi_image_url = []\n",
    "\n",
    "\n",
    "# Identify the hemishphere title and image url\n",
    "for result in valles_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        valles_name = result.find('h2', class_=\"title\").text\n",
    "        valles_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(valles_name)\n",
    "        hemi_image_url.append(hemi_url+valles_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")\n",
    "        \n",
    "valles_browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in schia_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        schia_name = result.find('h2', class_=\"title\").text\n",
    "        schia_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(schia_name)\n",
    "        hemi_image_url.append(hemi_url+schia_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")\n",
    "        \n",
    "schia_browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the hemishphere title and image url\n",
    "for result in syrt_results:\n",
    "    \n",
    "    # Error handling\n",
    "    try:\n",
    "        \n",
    "        #identify and return the title and image\n",
    "        syrt_name = result.find('h2', class_=\"title\").text\n",
    "        syrt_image = result.find('img', class_=\"wide-image\")['src']\n",
    "\n",
    "        #append values to dictionary\n",
    "        hemi_title.append(syrt_name)\n",
    "        hemi_image_url.append(hemi_url+syrt_image)\n",
    "\n",
    "    except AttributeError as e:\n",
    "        print(\"No Title Available\")\n",
    "        \n",
    "syrt_browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = [\n",
    "    {\"title\": hemi_title[0], \"img_url\": hemi_image_url[0]},\n",
    "    {\"title\": hemi_title[1], \"img_url\": hemi_image_url[1]},\n",
    "    {\"title\": hemi_title[2], \"img_url\": hemi_image_url[2]},\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
